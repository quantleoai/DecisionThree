{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f68a89",
   "metadata": {},
   "source": [
    "# Análise de Sessões de Trading com Decision Tree\n",
    "\n",
    "## Objetivo do Projeto\n",
    "Usar Machine Learning (Árvore de Decisão) para descobrir qual sessão de trading \n",
    "(Ásia, Londres ou Nova York) oferece as melhores oportunidades para EURUSD.\n",
    "\n",
    "### O que vamos fazer:\n",
    "1. **Preparação dos Dados**: Carregar e limpar dados históricos de EURUSD\n",
    "2. **Feature Engineering**: Criar métricas de volatilidade por sessão\n",
    "3. **Modelo de Classificação**: Prever qual sessão será a \"vencedora\" do dia\n",
    "4. **Modelo de Regressão**: Prever o tamanho do movimento em pips\n",
    "\n",
    "### Por que Decision Tree?\n",
    "- Fácil de interpretar (você pode visualizar as regras)\n",
    "- Não precisa de normalização dos dados\n",
    "- Bom ponto de partida para aprender ML aplicado a trading\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3ea40",
   "metadata": {},
   "source": [
    "## 1. IMPORTAÇÃO DAS BIBLIOTECAS\n",
    "\n",
    "Aqui importamos as ferramentas que vamos usar:\n",
    "- **pandas**: Manipulação de dados em formato de tabela (DataFrame)\n",
    "- **numpy**: Cálculos matemáticos e arrays\n",
    "- **matplotlib**: Criação de gráficos\n",
    "- **datetime**: Trabalhar com datas e horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IMPORTAÇÃO DAS BIBLIOTECAS\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd          # Manipulação de dados tabulares\n",
    "import numpy as np           # Cálculos numéricos\n",
    "import matplotlib.pyplot as plt  # Visualização de dados\n",
    "import datetime              # Manipulação de datas\n",
    "from datetime import date    # Trabalhar com datas específicas\n",
    "\n",
    "%matplotlib inline           # Exibe gráficos direto no notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4809f0",
   "metadata": {},
   "source": [
    "## 2. CARREGAMENTO DOS DADOS\n",
    "\n",
    "Carregamos o arquivo CSV com dados históricos de EURUSD no timeframe H1 (1 hora).\n",
    "\n",
    "**Parâmetros importantes:**\n",
    "- `delimiter=';'`: O arquivo usa ponto-e-vírgula como separador (comum em arquivos europeus)\n",
    "\n",
    "**Dica**: Sempre verifique o formato do seu arquivo CSV antes de carregar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CARREGAMENTO DOS DADOS\n",
    "# ============================================================\n",
    "\n",
    "# Lê o arquivo CSV com dados de EURUSD H1\n",
    "# delimiter=';' porque o arquivo usa ponto-e-vírgula como separador\n",
    "df = pd.read_csv(\"data/eurusd_h1.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica as dimensões do DataFrame: (linhas, colunas)\n",
    "# Esperamos ver algo como (22245, 5) - mais de 22 mil candles de 1 hora\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffb0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza as primeiras 5 linhas para entender a estrutura dos dados\n",
    "# Colunas esperadas: Date, Open, High, Low, Close\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b619399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estatísticas descritivas dos dados numéricos\n",
    "# Mostra: count, mean, std, min, 25%, 50%, 75%, max\n",
    "# Útil para identificar outliers ou erros nos dados\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa4546",
   "metadata": {},
   "source": [
    "## 3. TRATAMENTO DE DATAS\n",
    "\n",
    "A coluna 'Date' veio como texto (string). Precisamos converter para datetime\n",
    "para poder extrair informações como hora, dia da semana, etc.\n",
    "\n",
    "**ATENÇÃO ao formato da data!**\n",
    "- `dayfirst=True`: Indica que a data está no formato DD/MM/YYYY (padrão brasileiro)\n",
    "- Sem esse parâmetro, o pandas assume MM/DD/YYYY (padrão americano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONVERSÃO DA COLUNA DATE PARA DATETIME\n",
    "# ============================================================\n",
    "\n",
    "# Converte a coluna Date de string para datetime\n",
    "# dayfirst=True porque a data está no formato DD/MM/YYYY (brasileiro)\n",
    "# IMPORTANTE: Sem esse parâmetro, 01/02/2015 seria interpretado como 2 de janeiro!\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirma que a conversão funcionou\n",
    "# Agora deve mostrar datetime64[ns] para a coluna Date\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica os tipos de dados de cada coluna\n",
    "# Date deve ser datetime64[ns], os demais float64\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bcc762",
   "metadata": {},
   "source": [
    "## 4. VERIFICAÇÃO DO TIMEZONE DOS DADOS\n",
    "\n",
    "**Por que isso é importante?**\n",
    "- Precisamos saber em qual timezone os dados estão para classificar corretamente as sessões\n",
    "- Se os dados estão em UTC, a sessão de Londres começa às 08:00\n",
    "- Se estão em horário de Nova York, Londres começa às 03:00\n",
    "\n",
    "**Método de verificação:**\n",
    "1. Calculamos a volatilidade (Range = High - Low) para cada hora de um dia específico\n",
    "2. O pico de volatilidade deve coincidir com a abertura de Londres\n",
    "3. Se o pico está nas horas 8-9, os dados estão em UTC ✓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VERIFICAÇÃO DO TIMEZONE\n",
    "# ============================================================\n",
    "\n",
    "# Extrai a hora de cada candle\n",
    "hour = df[\"Date\"].dt.hour\n",
    "hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13891bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma data específica para análise\n",
    "# Escolhemos um dia aleatório no meio da semana (quarta-feira)\n",
    "date1 = date(2018, 7, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra apenas os candles desse dia específico\n",
    "df_dia = df[df['Date'].dt.date == date1]\n",
    "df_dia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a560ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona coluna 'hour' ao DataFrame principal\n",
    "# .dt.hour extrai apenas a hora do datetime\n",
    "df['hour'] = df['Date'].dt.hour\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o Range (volatilidade) para o dia de teste\n",
    "# Range = High - Low (amplitude do candle)\n",
    "df_dia['Range'] = df_dia['High'] - df_dia['Low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa por hora e calcula a média do Range\n",
    "# Isso mostra em qual hora a volatilidade é maior\n",
    "df_dia.groupby(df_dia['Date'].dt.hour)['Range'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7a7d3",
   "metadata": {},
   "source": [
    "### Conclusão do Timezone\n",
    "\n",
    "Se o pico de volatilidade está nas horas 8-9, **os dados estão em UTC**.\n",
    "\n",
    "Isso faz sentido porque:\n",
    "- Londres abre às 08:00 UTC\n",
    "- A volatilidade aumenta logo após a abertura\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb8e9ea",
   "metadata": {},
   "source": [
    "## 5. CLASSIFICAÇÃO DAS SESSÕES\n",
    "\n",
    "Agora que sabemos que os dados estão em UTC, podemos classificar cada candle\n",
    "em uma das três sessões principais:\n",
    "\n",
    "| Sessão | Horário UTC | Horas |\n",
    "|--------|-------------|-------|\n",
    "| **Ásia** | 00:00 - 07:59 | 0-7 |\n",
    "| **Londres** | 08:00 - 15:59 | 8-15 |\n",
    "| **Nova York** | 16:00 - 23:59 | 16-23 |\n",
    "\n",
    "**Nota**: Essa é uma simplificação. Na realidade, há overlap entre Londres e NY (13:00-17:00 UTC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNÇÃO DE CLASSIFICAÇÃO DAS SESSÕES\n",
    "# ============================================================\n",
    "\n",
    "def session_classification(h):\n",
    "    \"\"\"\n",
    "    Classifica a hora em uma das três sessões de trading.\n",
    "    \n",
    "    Parâmetros:\n",
    "        h (int): Hora do dia (0-23)\n",
    "    \n",
    "    Retorna:\n",
    "        str: Nome da sessão ('asia', 'london', ou 'ny')\n",
    "    \n",
    "    Sessões (em UTC):\n",
    "        - Ásia: 00:00 - 07:59\n",
    "        - Londres: 08:00 - 15:59  \n",
    "        - Nova York: 16:00 - 23:59\n",
    "    \"\"\"\n",
    "    if h >= 0 and h <= 7:\n",
    "        return 'asia'\n",
    "    elif h >= 8 and h <= 15:\n",
    "        return 'london'\n",
    "    else:\n",
    "        return 'ny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função a cada linha do DataFrame\n",
    "# .apply() executa a função para cada valor da coluna 'hour'\n",
    "df['Session'] = df['hour'].apply(session_classification)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f1b26",
   "metadata": {},
   "source": [
    "## 6. AGREGAÇÃO DOS DADOS POR SESSÃO\n",
    "\n",
    "Agora precisamos transformar os dados de H1 (24 candles por dia) em dados\n",
    "por sessão (3 \"candles\" por dia: Ásia, Londres, NY).\n",
    "\n",
    "**O que fazemos:**\n",
    "1. Criamos uma coluna 'Data' apenas com a data (sem hora)\n",
    "2. Agrupamos por Data + Sessão\n",
    "3. Para cada grupo, calculamos:\n",
    "   - **High**: máximo do período\n",
    "   - **Low**: mínimo do período\n",
    "   - **Open**: primeiro valor do período\n",
    "   - **Close**: último valor do período"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CRIAÇÃO DA COLUNA 'DATA' (APENAS DATA, SEM HORA)\n",
    "# ============================================================\n",
    "\n",
    "# Extrai apenas a data (sem hora) para agrupar os candles do mesmo dia\n",
    "# .dt.date retorna apenas a parte da data do datetime\n",
    "df['Data'] = df['Date'].dt.date\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AGREGAÇÃO DOS DADOS POR DIA E SESSÃO\n",
    "# ============================================================\n",
    "\n",
    "# Agrupa os dados por Data e Sessão, calculando OHLC de cada sessão\n",
    "# - High: valor máximo (max) - maior preço da sessão\n",
    "# - Low: valor mínimo (min) - menor preço da sessão  \n",
    "# - Open: primeiro valor (first) - preço de abertura da sessão\n",
    "# - Close: último valor (last) - preço de fechamento da sessão\n",
    "\n",
    "df_session = df.groupby(['Data', 'Session']).agg({\n",
    "    'High': 'max',      # Maior preço da sessão\n",
    "    'Low': 'min',       # Menor preço da sessão\n",
    "    'Open': 'first',    # Preço de abertura (primeiro candle)\n",
    "    'Close': 'last'     # Preço de fechamento (último candle)\n",
    "})\n",
    "\n",
    "df_session.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681bc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte o índice (Data, Session) de volta para colunas\n",
    "# Isso facilita a manipulação dos dados posteriormente\n",
    "df_session.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac4aea",
   "metadata": {},
   "source": [
    "## 7. FEATURE ENGINEERING (Criação de Variáveis)\n",
    "\n",
    "Aqui criamos as métricas que vão alimentar nosso modelo de ML:\n",
    "\n",
    "| Feature | Fórmula | Significado |\n",
    "|---------|---------|-------------|\n",
    "| **Range** | High - Low | Volatilidade total da sessão (em pips) |\n",
    "| **Movimento** | abs(Close - Open) | Movimento direcional (em pips) |\n",
    "| **Ratio** | Movimento / Range | Eficiência do movimento (0 a 1) |\n",
    "\n",
    "**Por que o Ratio é importante?**\n",
    "- Ratio = 1: O preço foi direto de Open para Close (movimento limpo)\n",
    "- Ratio = 0: O preço oscilou muito mas não saiu do lugar (movimento errático)\n",
    "\n",
    "**Sessão \"vencedora\"**: A sessão com maior Movimento no dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CRIAÇÃO DAS FEATURES (VARIÁVEIS PREDITORAS)\n",
    "# ============================================================\n",
    "\n",
    "# Range: Volatilidade total da sessão (High - Low)\n",
    "# Representa quantos pips o preço variou na sessão\n",
    "df_session['Range'] = df_session['High'] - df_session['Low']\n",
    "\n",
    "# Movimento: Quanto o preço andou de forma direcional\n",
    "# abs() garante valor positivo independente da direção (alta ou baixa)\n",
    "df_session['Movimento'] = abs(df_session['Open'] - df_session['Close'])\n",
    "\n",
    "# Ratio: Eficiência do movimento (quanto do range foi aproveitado)\n",
    "# Ratio = 1: movimento limpo | Ratio próximo de 0: muito ruído\n",
    "df_session['Ratio'] = df_session['Movimento'] / df_session['Range']\n",
    "\n",
    "print(df_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416f779",
   "metadata": {},
   "source": [
    "## 8. IDENTIFICAÇÃO DA SESSÃO VENCEDORA\n",
    "\n",
    "Para criar nosso target (variável que queremos prever), precisamos identificar\n",
    "qual sessão teve o maior movimento em cada dia.\n",
    "\n",
    "**Método:**\n",
    "1. Para cada dia, encontramos o valor máximo de 'Movimento'\n",
    "2. Marcamos como True a sessão que tem esse valor máximo\n",
    "3. Criamos o target com o nome da sessão vencedora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37403de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IDENTIFICAÇÃO DA SESSÃO VENCEDORA DE CADA DIA\n",
    "# ============================================================\n",
    "\n",
    "# transform('max') encontra o valor máximo de cada grupo (dia)\n",
    "# e \"espalha\" esse valor para todas as linhas do grupo\n",
    "# Isso permite comparar cada sessão com o máximo do dia\n",
    "target = df_session.groupby('Data')['Movimento'].transform('max')\n",
    "target2 = df_session.groupby('Data')['Ratio'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria colunas booleanas indicando se a sessão foi a vencedora\n",
    "# Vencedora1: baseada no Movimento (nossa métrica principal)\n",
    "# Vencedora2: baseada no Ratio (métrica alternativa)\n",
    "df_session['Vencedora1'] = df_session['Movimento'] == target\n",
    "df_session['Vencedora2'] = df_session['Ratio'] == target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e2ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza o resultado - agora cada sessão tem True/False\n",
    "# indicando se foi a vencedora do dia\n",
    "df_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3cd2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra dias onde a mesma sessão venceu em ambas as métricas\n",
    "# Esses são os \"dias mais claros\" onde uma sessão dominou\n",
    "df_session[(df_session['Vencedora1']) & (df_session['Vencedora2']) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b320e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CRIAÇÃO DO DATAFRAME DE VENCEDORAS\n",
    "# ============================================================\n",
    "\n",
    "# Filtra apenas as sessões que foram vencedoras (baseado em Movimento)\n",
    "df_vencedoras = df_session[df_session['Vencedora1']]\n",
    "\n",
    "# Reset do índice para facilitar manipulação\n",
    "df_vencedoras = df_vencedoras.reset_index()\n",
    "\n",
    "# Mantém apenas Data e Session (o que precisamos para o merge)\n",
    "df_vencedoras = df_vencedoras[['Data', 'Session']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d59f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vencedoras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fba598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ANÁLISE DA DISTRIBUIÇÃO DAS SESSÕES VENCEDORAS\n",
    "# ============================================================\n",
    "\n",
    "# Conta quantas vezes cada sessão foi a vencedora\n",
    "# Este é um insight MUITO importante para trading!\n",
    "df_vencedoras['Session'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36db3787",
   "metadata": {},
   "source": [
    "### Insight Importante!\n",
    "\n",
    "A distribuição das sessões vencedoras mostra algo interessante:\n",
    "- **Londres**: ~46% (mais frequente)\n",
    "- **NY**: ~42%\n",
    "- **Ásia**: ~12% (raramente vence)\n",
    "\n",
    "**Conclusão para trading**: Para EURUSD, focar em Londres e NY faz muito mais sentido\n",
    "do que operar na sessão asiática!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902633e",
   "metadata": {},
   "source": [
    "## 9. PREPARAÇÃO FINAL DOS DADOS\n",
    "\n",
    "Agora precisamos:\n",
    "1. Adicionar o dia da semana como feature\n",
    "2. Fazer merge para adicionar o 'Target' (sessão vencedora) ao dataset principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d202ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ADIÇÃO DO DIA DA SEMANA\n",
    "# ============================================================\n",
    "\n",
    "# Reset do índice para ter Data e Session como colunas\n",
    "df_session = df_session.reset_index()\n",
    "\n",
    "# Extrai o dia da semana (0=Segunda, 1=Terça, ..., 6=Domingo)\n",
    "# Isso pode revelar padrões como \"NY performa melhor nas sextas\"\n",
    "df_session['DiaSemana'] = df_session['Data'].apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ceeeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MERGE: ADICIONA O TARGET AO DATAFRAME PRINCIPAL\n",
    "# ============================================================\n",
    "\n",
    "# Merge junta duas tabelas baseado em uma coluna comum\n",
    "# Aqui, para cada Data em df_session, pegamos a Session vencedora de df_vencedoras\n",
    "# how='left' mantém todas as linhas de df_session mesmo se não houver match\n",
    "df_session = df_session.merge(df_vencedoras, on='Data', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b190bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba2576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RENOMEAÇÃO DAS COLUNAS\n",
    "# ============================================================\n",
    "\n",
    "# Após o merge, temos Session_x (sessão atual) e Session_y (sessão vencedora)\n",
    "# Renomeamos para nomes mais claros\n",
    "df_session = df_session.rename(columns={\n",
    "    'Session_x': 'Session',  # Sessão da linha atual\n",
    "    'Session_y': 'Target'    # Sessão vencedora do dia (o que queremos prever)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eaef35",
   "metadata": {},
   "source": [
    "## 10. MODELO 1: CLASSIFICAÇÃO\n",
    "\n",
    "### Objetivo\n",
    "Prever qual sessão será a vencedora do dia.\n",
    "\n",
    "### Tipo de Problema\n",
    "**Classificação Multiclasse** - Temos 3 classes possíveis: asia, london, ny\n",
    "\n",
    "### Features (X) vs Target (y)\n",
    "- **X (features)**: Range, Movimento, Ratio, DiaSemana\n",
    "- **y (target)**: Target (nome da sessão vencedora)\n",
    "\n",
    "### Train/Test Split\n",
    "Dividimos os dados em:\n",
    "- **70% para treino**: O modelo aprende os padrões\n",
    "- **30% para teste**: Avaliamos se o modelo generaliza\n",
    "\n",
    "**IMPORTANTE**: `shuffle=False` porque são dados temporais!\n",
    "Não podemos usar dados do futuro para prever o passado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPARAÇÃO DOS DADOS PARA O MODELO DE CLASSIFICAÇÃO\n",
    "# ============================================================\n",
    "\n",
    "# Seleciona as features (variáveis preditoras)\n",
    "# Usamos Range, Movimento, Ratio e DiaSemana para prever a sessão vencedora\n",
    "x = df_session[['Range', 'Movimento', 'Ratio', 'DiaSemana']]\n",
    "\n",
    "# Seleciona o target (o que queremos prever)\n",
    "y = df_session['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8514c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DIVISÃO TREINO/TESTE\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide os dados em treino (70%) e teste (30%)\n",
    "# test_size=0.3: 30% dos dados para teste\n",
    "# shuffle=False: NÃO embaralha os dados (CRÍTICO para séries temporais!)\n",
    "#   - Se shuffle=True, usaríamos dados de 2018 para prever 2015 (data leakage)\n",
    "# random_state=42: semente para reproducibilidade\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size=0.3,\n",
    "    shuffle=False,  # IMPORTANTE: manter ordem temporal\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f10e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica as dimensões após o split\n",
    "print(f\"Treino: {x_train.shape[0]} amostras\")\n",
    "print(f\"Teste: {x_test.shape[0]} amostras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4645af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TREINAMENTO DO MODELO DE CLASSIFICAÇÃO\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Cria o modelo de árvore de decisão\n",
    "# max_depth=4: limita a profundidade da árvore para evitar overfitting\n",
    "#              e facilitar a interpretação\n",
    "mod_arvore = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "\n",
    "# Treina o modelo com os dados de treino\n",
    "# .fit() é onde o modelo \"aprende\" os padrões\n",
    "mod_arvore.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREVISÕES\n",
    "# ============================================================\n",
    "\n",
    "# Faz previsões nos dados de treino (para comparar com teste)\n",
    "y_pred_train = mod_arvore.predict(x_train)\n",
    "\n",
    "# Faz previsões nos dados de teste (avaliação real)\n",
    "y_pred_test = mod_arvore.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AVALIAÇÃO DO MODELO - ACURÁCIA\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Acurácia: percentual de previsões corretas\n",
    "# Comparamos com baseline aleatório (33% para 3 classes)\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Acurácia no Treino: {acc_train:.2%}\")\n",
    "print(f\"Acurácia no Teste: {acc_test:.2%}\")\n",
    "print(f\"\\nBaseline aleatório: 33.33%\")\n",
    "print(f\"Melhoria sobre baseline: {(acc_test - 0.3333) / 0.3333:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AVALIAÇÃO DO MODELO - MATRIZ DE CONFUSÃO\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matriz de confusão mostra onde o modelo acerta e erra\n",
    "# Linhas: valores reais | Colunas: valores previstos\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "# Relatório detalhado com precision, recall e f1-score\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b6590",
   "metadata": {},
   "source": [
    "### Interpretação da Matriz de Confusão\n",
    "\n",
    "A matriz de confusão mostra:\n",
    "- **Diagonal principal**: Acertos (previsão = real)\n",
    "- **Fora da diagonal**: Erros\n",
    "\n",
    "**Métricas importantes:**\n",
    "- **Precision**: Dos que o modelo disse que eram X, quantos realmente eram X?\n",
    "- **Recall**: Dos que realmente eram X, quantos o modelo identificou?\n",
    "- **F1-Score**: Média harmônica entre precision e recall\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d389c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZAÇÃO DA ÁRVORE DE DECISÃO\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Cria figura grande para melhor visualização\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plota a árvore de decisão\n",
    "# feature_names: nomes das features para aparecer nos nós\n",
    "# class_names: nomes das classes para aparecer nas folhas\n",
    "# filled=True: colore os nós de acordo com a classe majoritária\n",
    "# rounded=True: bordas arredondadas\n",
    "plot_tree(\n",
    "    mod_arvore,\n",
    "    feature_names=x.columns.tolist(),\n",
    "    class_names=['asia', 'london', 'ny'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "plt.title(\"Árvore de Decisão - Classificação de Sessões EURUSD\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8204693",
   "metadata": {},
   "source": [
    "## 11. MODELO 2: REGRESSÃO\n",
    "\n",
    "### Objetivo\n",
    "Prever o tamanho do movimento (em pips) de cada sessão.\n",
    "\n",
    "### Tipo de Problema\n",
    "**Regressão** - O target é um valor contínuo (não categorias)\n",
    "\n",
    "### Features (X2) vs Target (y2)\n",
    "- **X2 (features)**: DiaSemana, Session (convertida para número)\n",
    "- **y2 (target)**: Movimento (valor contínuo)\n",
    "\n",
    "### CUIDADO: Evitando Data Leakage!\n",
    "NÃO usamos Range ou Ratio como features porque:\n",
    "- Range e Movimento são calculados ao mesmo tempo\n",
    "- Usar Range para prever Movimento seria \"trapacear\"\n",
    "- Na vida real, você não sabe o Range antes da sessão acabar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d6396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPARAÇÃO DOS DADOS PARA REGRESSÃO\n",
    "# ============================================================\n",
    "\n",
    "# Converte Session para número (o modelo precisa de dados numéricos)\n",
    "# asia=0, london=1, ny=2\n",
    "session_map = {'asia': 0, 'london': 1, 'ny': 2}\n",
    "df_session['Session_num'] = df_session['Session'].map(session_map)\n",
    "\n",
    "# Features: apenas DiaSemana e Session_num\n",
    "# NÃO usamos Range/Ratio para evitar data leakage!\n",
    "x2 = df_session[['DiaSemana', 'Session_num']]\n",
    "\n",
    "# Target: Movimento (o que queremos prever)\n",
    "y2 = df_session['Movimento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DIVISÃO TREINO/TESTE PARA REGRESSÃO\n",
    "# ============================================================\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(\n",
    "    x2, y2,\n",
    "    test_size=0.3,\n",
    "    shuffle=False,  # Mantém ordem temporal\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TREINAMENTO DO MODELO DE REGRESSÃO\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# DecisionTreeRegressor para valores contínuos\n",
    "# max_depth=4: mesma ideia de limitar complexidade\n",
    "mod_arvore2 = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "\n",
    "# Treina o modelo\n",
    "mod_arvore2.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7522db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREVISÕES DO MODELO DE REGRESSÃO\n",
    "# ============================================================\n",
    "\n",
    "y_pred_train2 = mod_arvore2.predict(x_train2)\n",
    "y_pred_test2 = mod_arvore2.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZAÇÃO DA ÁRVORE DE REGRESSÃO\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plot_tree(\n",
    "    mod_arvore2,\n",
    "    feature_names=['DiaSemana', 'Session_num'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "plt.title(\"Árvore de Decisão - Regressão do Movimento EURUSD\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19846ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPARAÇÃO: VALORES REAIS VS PREVISTOS\n",
    "# ============================================================\n",
    "\n",
    "# Cria DataFrame para comparar previsões com valores reais\n",
    "df2_aval = pd.DataFrame({\n",
    "    'Real': y_test2,\n",
    "    'Previsto': y_pred_test2\n",
    "})\n",
    "df2_aval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca10b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AVALIAÇÃO DO MODELO DE REGRESSÃO\n",
    "# ============================================================\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# MAE (Mean Absolute Error): Erro médio em valor absoluto\n",
    "# Quanto menor, melhor\n",
    "mae = metrics.mean_absolute_error(y_test2, y_pred_test2)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# RMSE (Root Mean Squared Error): Penaliza mais erros grandes\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_pred_test2))\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VERIFICAÇÃO DE OVERFITTING\n",
    "# ============================================================\n",
    "\n",
    "# Compara erro no treino vs teste\n",
    "# Se erro_treino << erro_teste: OVERFITTING (modelo decorou os dados)\n",
    "# Se erro_treino ≈ erro_teste: OK (modelo generaliza bem)\n",
    "\n",
    "mae_train = metrics.mean_absolute_error(y_train2, mod_arvore2.predict(x_train2))\n",
    "mae_test = metrics.mean_absolute_error(y_test2, y_pred_test2)\n",
    "\n",
    "print(f'MAE - Treinamento: {mae_train}')\n",
    "print(f'MAE - Teste: {mae_test}')\n",
    "\n",
    "if mae_train * 1.1 < mae_test:\n",
    "    print(\"\\n ATENÇÃO: Possível overfitting!\")\n",
    "else:\n",
    "    print(\"\\n Modelo generaliza bem (sem overfitting)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# INTERPRETAÇÃO DO ERRO\n",
    "# ============================================================\n",
    "\n",
    "# Calcula o MAE como percentual da média\n",
    "# Isso dá uma ideia de quão \"grande\" é o erro em termos relativos\n",
    "\n",
    "media_movimento = y_test2.mean()\n",
    "print(f\"Média do Movimento: {media_movimento}\")\n",
    "print()\n",
    "\n",
    "erro_percentual = mae / media_movimento * 100\n",
    "print(f'O percentual do MAE em relação à média da base:')\n",
    "print(f'{erro_percentual:.2f}%')\n",
    "print()\n",
    "print(f\"Interpretação: O modelo erra em média {erro_percentual:.1f}% do movimento real.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b09b7a",
   "metadata": {},
   "source": [
    "## 12. CONCLUSÕES E PRÓXIMOS PASSOS\n",
    "\n",
    "### Resultados do Modelo de Classificação\n",
    "- **Acurácia**: ~41% (vs 33% aleatório)\n",
    "- O modelo é ~24% melhor que chute aleatório\n",
    "- Londres e NY são mais previsíveis que Ásia\n",
    "\n",
    "### Resultados do Modelo de Regressão\n",
    "- **MAE**: ~7.5% do movimento médio\n",
    "- Sem overfitting (erro treino ≈ erro teste)\n",
    "\n",
    "### Insights para Trading\n",
    "1. **Foque em Londres e NY** para EURUSD - juntas vencem 88% dos dias\n",
    "2. **Ásia é imprevisível** - apenas 12% de vitórias, modelo falha muito\n",
    "3. **Padrões existem mas são fracos** - 41% não é suficiente para trading real\n",
    "\n",
    "### Próximos Passos\n",
    "1. Adicionar mais features (volatilidade do dia anterior, eventos econômicos)\n",
    "2. Testar outros modelos (Random Forest, XGBoost)\n",
    "3. Fazer backtesting com os sinais gerados\n",
    "4. Incluir custos de transação na avaliação\n",
    "\n",
    "---\n",
    "\n",
    "**Leonardo Alves**: Dados, não opiniões! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
