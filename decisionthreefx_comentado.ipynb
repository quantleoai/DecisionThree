{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57f68a89",
   "metadata": {},
   "source": [
    "# AnÃ¡lise de SessÃµes de Trading com Decision Tree\n",
    "\n",
    "## Objetivo do Projeto\n",
    "Usar Machine Learning (Ãrvore de DecisÃ£o) para descobrir qual sessÃ£o de trading \n",
    "(Ãsia, Londres ou Nova York) oferece as melhores oportunidades para EURUSD.\n",
    "\n",
    "### O que vamos fazer:\n",
    "1. **PreparaÃ§Ã£o dos Dados**: Carregar e limpar dados histÃ³ricos de EURUSD\n",
    "2. **Feature Engineering**: Criar mÃ©tricas de volatilidade por sessÃ£o\n",
    "3. **Modelo de ClassificaÃ§Ã£o**: Prever qual sessÃ£o serÃ¡ a \"vencedora\" do dia\n",
    "4. **Modelo de RegressÃ£o**: Prever o tamanho do movimento em pips\n",
    "\n",
    "### Por que Decision Tree?\n",
    "- FÃ¡cil de interpretar (vocÃª pode visualizar as regras)\n",
    "- NÃ£o precisa de normalizaÃ§Ã£o dos dados\n",
    "- Bom ponto de partida para aprender ML aplicado a trading\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3ea40",
   "metadata": {},
   "source": [
    "## 1. IMPORTAÃ‡ÃƒO DAS BIBLIOTECAS\n",
    "\n",
    "Aqui importamos as ferramentas que vamos usar:\n",
    "- **pandas**: ManipulaÃ§Ã£o de dados em formato de tabela (DataFrame)\n",
    "- **numpy**: CÃ¡lculos matemÃ¡ticos e arrays\n",
    "- **matplotlib**: CriaÃ§Ã£o de grÃ¡ficos\n",
    "- **datetime**: Trabalhar com datas e horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IMPORTAÃ‡ÃƒO DAS BIBLIOTECAS\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd          # ManipulaÃ§Ã£o de dados tabulares\n",
    "import numpy as np           # CÃ¡lculos numÃ©ricos\n",
    "import matplotlib.pyplot as plt  # VisualizaÃ§Ã£o de dados\n",
    "import datetime              # ManipulaÃ§Ã£o de datas\n",
    "from datetime import date    # Trabalhar com datas especÃ­ficas\n",
    "\n",
    "%matplotlib inline           # Exibe grÃ¡ficos direto no notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4809f0",
   "metadata": {},
   "source": [
    "## 2. CARREGAMENTO DOS DADOS\n",
    "\n",
    "Carregamos o arquivo CSV com dados histÃ³ricos de EURUSD no timeframe H1 (1 hora).\n",
    "\n",
    "**ParÃ¢metros importantes:**\n",
    "- `delimiter=';'`: O arquivo usa ponto-e-vÃ­rgula como separador (comum em arquivos europeus)\n",
    "\n",
    "**Dica**: Sempre verifique o formato do seu arquivo CSV antes de carregar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be2c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CARREGAMENTO DOS DADOS\n",
    "# ============================================================\n",
    "\n",
    "# LÃª o arquivo CSV com dados de EURUSD H1\n",
    "# delimiter=';' porque o arquivo usa ponto-e-vÃ­rgula como separador\n",
    "df = pd.read_csv(\"data/eurusd_h1.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cc403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica as dimensÃµes do DataFrame: (linhas, colunas)\n",
    "# Esperamos ver algo como (22245, 5) - mais de 22 mil candles de 1 hora\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ffb0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza as primeiras 5 linhas para entender a estrutura dos dados\n",
    "# Colunas esperadas: Date, Open, High, Low, Close\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b619399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EstatÃ­sticas descritivas dos dados numÃ©ricos\n",
    "# Mostra: count, mean, std, min, 25%, 50%, 75%, max\n",
    "# Ãštil para identificar outliers ou erros nos dados\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa4546",
   "metadata": {},
   "source": [
    "## 3. TRATAMENTO DE DATAS\n",
    "\n",
    "A coluna 'Date' veio como texto (string). Precisamos converter para datetime\n",
    "para poder extrair informaÃ§Ãµes como hora, dia da semana, etc.\n",
    "\n",
    "**ATENÃ‡ÃƒO ao formato da data!**\n",
    "- `dayfirst=True`: Indica que a data estÃ¡ no formato DD/MM/YYYY (padrÃ£o brasileiro)\n",
    "- Sem esse parÃ¢metro, o pandas assume MM/DD/YYYY (padrÃ£o americano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONVERSÃƒO DA COLUNA DATE PARA DATETIME\n",
    "# ============================================================\n",
    "\n",
    "# Converte a coluna Date de string para datetime\n",
    "# dayfirst=True porque a data estÃ¡ no formato DD/MM/YYYY (brasileiro)\n",
    "# IMPORTANTE: Sem esse parÃ¢metro, 01/02/2015 seria interpretado como 2 de janeiro!\n",
    "df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirma que a conversÃ£o funcionou\n",
    "# Agora deve mostrar datetime64[ns] para a coluna Date\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a0bf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica os tipos de dados de cada coluna\n",
    "# Date deve ser datetime64[ns], os demais float64\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bcc762",
   "metadata": {},
   "source": [
    "## 4. VERIFICAÃ‡ÃƒO DO TIMEZONE DOS DADOS\n",
    "\n",
    "**Por que isso Ã© importante?**\n",
    "- Precisamos saber em qual timezone os dados estÃ£o para classificar corretamente as sessÃµes\n",
    "- Se os dados estÃ£o em UTC, a sessÃ£o de Londres comeÃ§a Ã s 08:00\n",
    "- Se estÃ£o em horÃ¡rio de Nova York, Londres comeÃ§a Ã s 03:00\n",
    "\n",
    "**MÃ©todo de verificaÃ§Ã£o:**\n",
    "1. Calculamos a volatilidade (Range = High - Low) para cada hora de um dia especÃ­fico\n",
    "2. O pico de volatilidade deve coincidir com a abertura de Londres\n",
    "3. Se o pico estÃ¡ nas horas 8-9, os dados estÃ£o em UTC âœ“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VERIFICAÃ‡ÃƒO DO TIMEZONE\n",
    "# ============================================================\n",
    "\n",
    "# Extrai a hora de cada candle\n",
    "hour = df[\"Date\"].dt.hour\n",
    "hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13891bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria uma data especÃ­fica para anÃ¡lise\n",
    "# Escolhemos um dia aleatÃ³rio no meio da semana (quarta-feira)\n",
    "date1 = date(2018, 7, 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c47f9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra apenas os candles desse dia especÃ­fico\n",
    "df_dia = df[df['Date'].dt.date == date1]\n",
    "df_dia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a560ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adiciona coluna 'hour' ao DataFrame principal\n",
    "# .dt.hour extrai apenas a hora do datetime\n",
    "df['hour'] = df['Date'].dt.hour\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a665c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o Range (volatilidade) para o dia de teste\n",
    "# Range = High - Low (amplitude do candle)\n",
    "df_dia['Range'] = df_dia['High'] - df_dia['Low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupa por hora e calcula a mÃ©dia do Range\n",
    "# Isso mostra em qual hora a volatilidade Ã© maior\n",
    "df_dia.groupby(df_dia['Date'].dt.hour)['Range'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7a7d3",
   "metadata": {},
   "source": [
    "### ConclusÃ£o do Timezone\n",
    "\n",
    "Se o pico de volatilidade estÃ¡ nas horas 8-9, **os dados estÃ£o em UTC**.\n",
    "\n",
    "Isso faz sentido porque:\n",
    "- Londres abre Ã s 08:00 UTC\n",
    "- A volatilidade aumenta logo apÃ³s a abertura\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb8e9ea",
   "metadata": {},
   "source": [
    "## 5. CLASSIFICAÃ‡ÃƒO DAS SESSÃ•ES\n",
    "\n",
    "Agora que sabemos que os dados estÃ£o em UTC, podemos classificar cada candle\n",
    "em uma das trÃªs sessÃµes principais:\n",
    "\n",
    "| SessÃ£o | HorÃ¡rio UTC | Horas |\n",
    "|--------|-------------|-------|\n",
    "| **Ãsia** | 00:00 - 07:59 | 0-7 |\n",
    "| **Londres** | 08:00 - 15:59 | 8-15 |\n",
    "| **Nova York** | 16:00 - 23:59 | 16-23 |\n",
    "\n",
    "**Nota**: Essa Ã© uma simplificaÃ§Ã£o. Na realidade, hÃ¡ overlap entre Londres e NY (13:00-17:00 UTC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b828c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FUNÃ‡ÃƒO DE CLASSIFICAÃ‡ÃƒO DAS SESSÃ•ES\n",
    "# ============================================================\n",
    "\n",
    "def session_classification(h):\n",
    "    \"\"\"\n",
    "    Classifica a hora em uma das trÃªs sessÃµes de trading.\n",
    "    \n",
    "    ParÃ¢metros:\n",
    "        h (int): Hora do dia (0-23)\n",
    "    \n",
    "    Retorna:\n",
    "        str: Nome da sessÃ£o ('asia', 'london', ou 'ny')\n",
    "    \n",
    "    SessÃµes (em UTC):\n",
    "        - Ãsia: 00:00 - 07:59\n",
    "        - Londres: 08:00 - 15:59  \n",
    "        - Nova York: 16:00 - 23:59\n",
    "    \"\"\"\n",
    "    if h >= 0 and h <= 7:\n",
    "        return 'asia'\n",
    "    elif h >= 8 and h <= 15:\n",
    "        return 'london'\n",
    "    else:\n",
    "        return 'ny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c059c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a funÃ§Ã£o a cada linha do DataFrame\n",
    "# .apply() executa a funÃ§Ã£o para cada valor da coluna 'hour'\n",
    "df['Session'] = df['hour'].apply(session_classification)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f1b26",
   "metadata": {},
   "source": [
    "## 6. AGREGAÃ‡ÃƒO DOS DADOS POR SESSÃƒO\n",
    "\n",
    "Agora precisamos transformar os dados de H1 (24 candles por dia) em dados\n",
    "por sessÃ£o (3 \"candles\" por dia: Ãsia, Londres, NY).\n",
    "\n",
    "**O que fazemos:**\n",
    "1. Criamos uma coluna 'Data' apenas com a data (sem hora)\n",
    "2. Agrupamos por Data + SessÃ£o\n",
    "3. Para cada grupo, calculamos:\n",
    "   - **High**: mÃ¡ximo do perÃ­odo\n",
    "   - **Low**: mÃ­nimo do perÃ­odo\n",
    "   - **Open**: primeiro valor do perÃ­odo\n",
    "   - **Close**: Ãºltimo valor do perÃ­odo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CRIAÃ‡ÃƒO DA COLUNA 'DATA' (APENAS DATA, SEM HORA)\n",
    "# ============================================================\n",
    "\n",
    "# Extrai apenas a data (sem hora) para agrupar os candles do mesmo dia\n",
    "# .dt.date retorna apenas a parte da data do datetime\n",
    "df['Data'] = df['Date'].dt.date\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AGREGAÃ‡ÃƒO DOS DADOS POR DIA E SESSÃƒO\n",
    "# ============================================================\n",
    "\n",
    "# Agrupa os dados por Data e SessÃ£o, calculando OHLC de cada sessÃ£o\n",
    "# - High: valor mÃ¡ximo (max) - maior preÃ§o da sessÃ£o\n",
    "# - Low: valor mÃ­nimo (min) - menor preÃ§o da sessÃ£o  \n",
    "# - Open: primeiro valor (first) - preÃ§o de abertura da sessÃ£o\n",
    "# - Close: Ãºltimo valor (last) - preÃ§o de fechamento da sessÃ£o\n",
    "\n",
    "df_session = df.groupby(['Data', 'Session']).agg({\n",
    "    'High': 'max',      # Maior preÃ§o da sessÃ£o\n",
    "    'Low': 'min',       # Menor preÃ§o da sessÃ£o\n",
    "    'Open': 'first',    # PreÃ§o de abertura (primeiro candle)\n",
    "    'Close': 'last'     # PreÃ§o de fechamento (Ãºltimo candle)\n",
    "})\n",
    "\n",
    "df_session.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681bc1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte o Ã­ndice (Data, Session) de volta para colunas\n",
    "# Isso facilita a manipulaÃ§Ã£o dos dados posteriormente\n",
    "df_session.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddac4aea",
   "metadata": {},
   "source": [
    "## 7. FEATURE ENGINEERING (CriaÃ§Ã£o de VariÃ¡veis)\n",
    "\n",
    "Aqui criamos as mÃ©tricas que vÃ£o alimentar nosso modelo de ML:\n",
    "\n",
    "| Feature | FÃ³rmula | Significado |\n",
    "|---------|---------|-------------|\n",
    "| **Range** | High - Low | Volatilidade total da sessÃ£o (em pips) |\n",
    "| **Movimento** | abs(Close - Open) | Movimento direcional (em pips) |\n",
    "| **Ratio** | Movimento / Range | EficiÃªncia do movimento (0 a 1) |\n",
    "\n",
    "**Por que o Ratio Ã© importante?**\n",
    "- Ratio = 1: O preÃ§o foi direto de Open para Close (movimento limpo)\n",
    "- Ratio = 0: O preÃ§o oscilou muito mas nÃ£o saiu do lugar (movimento errÃ¡tico)\n",
    "\n",
    "**SessÃ£o \"vencedora\"**: A sessÃ£o com maior Movimento no dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CRIAÃ‡ÃƒO DAS FEATURES (VARIÃVEIS PREDITORAS)\n",
    "# ============================================================\n",
    "\n",
    "# Range: Volatilidade total da sessÃ£o (High - Low)\n",
    "# Representa quantos pips o preÃ§o variou na sessÃ£o\n",
    "df_session['Range'] = df_session['High'] - df_session['Low']\n",
    "\n",
    "# Movimento: Quanto o preÃ§o andou de forma direcional\n",
    "# abs() garante valor positivo independente da direÃ§Ã£o (alta ou baixa)\n",
    "df_session['Movimento'] = abs(df_session['Open'] - df_session['Close'])\n",
    "\n",
    "# Ratio: EficiÃªncia do movimento (quanto do range foi aproveitado)\n",
    "# Ratio = 1: movimento limpo | Ratio prÃ³ximo de 0: muito ruÃ­do\n",
    "df_session['Ratio'] = df_session['Movimento'] / df_session['Range']\n",
    "\n",
    "print(df_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416f779",
   "metadata": {},
   "source": [
    "## 8. IDENTIFICAÃ‡ÃƒO DA SESSÃƒO VENCEDORA\n",
    "\n",
    "Para criar nosso target (variÃ¡vel que queremos prever), precisamos identificar\n",
    "qual sessÃ£o teve o maior movimento em cada dia.\n",
    "\n",
    "**MÃ©todo:**\n",
    "1. Para cada dia, encontramos o valor mÃ¡ximo de 'Movimento'\n",
    "2. Marcamos como True a sessÃ£o que tem esse valor mÃ¡ximo\n",
    "3. Criamos o target com o nome da sessÃ£o vencedora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37403de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IDENTIFICAÃ‡ÃƒO DA SESSÃƒO VENCEDORA DE CADA DIA\n",
    "# ============================================================\n",
    "\n",
    "# transform('max') encontra o valor mÃ¡ximo de cada grupo (dia)\n",
    "# e \"espalha\" esse valor para todas as linhas do grupo\n",
    "# Isso permite comparar cada sessÃ£o com o mÃ¡ximo do dia\n",
    "target = df_session.groupby('Data')['Movimento'].transform('max')\n",
    "target2 = df_session.groupby('Data')['Ratio'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a4102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria colunas booleanas indicando se a sessÃ£o foi a vencedora\n",
    "# Vencedora1: baseada no Movimento (nossa mÃ©trica principal)\n",
    "# Vencedora2: baseada no Ratio (mÃ©trica alternativa)\n",
    "df_session['Vencedora1'] = df_session['Movimento'] == target\n",
    "df_session['Vencedora2'] = df_session['Ratio'] == target2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e2ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza o resultado - agora cada sessÃ£o tem True/False\n",
    "# indicando se foi a vencedora do dia\n",
    "df_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3cd2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtra dias onde a mesma sessÃ£o venceu em ambas as mÃ©tricas\n",
    "# Esses sÃ£o os \"dias mais claros\" onde uma sessÃ£o dominou\n",
    "df_session[(df_session['Vencedora1']) & (df_session['Vencedora2']) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b320e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CRIAÃ‡ÃƒO DO DATAFRAME DE VENCEDORAS\n",
    "# ============================================================\n",
    "\n",
    "# Filtra apenas as sessÃµes que foram vencedoras (baseado em Movimento)\n",
    "df_vencedoras = df_session[df_session['Vencedora1']]\n",
    "\n",
    "# Reset do Ã­ndice para facilitar manipulaÃ§Ã£o\n",
    "df_vencedoras = df_vencedoras.reset_index()\n",
    "\n",
    "# MantÃ©m apenas Data e Session (o que precisamos para o merge)\n",
    "df_vencedoras = df_vencedoras[['Data', 'Session']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d59f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vencedoras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fba598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ANÃLISE DA DISTRIBUIÃ‡ÃƒO DAS SESSÃ•ES VENCEDORAS\n",
    "# ============================================================\n",
    "\n",
    "# Conta quantas vezes cada sessÃ£o foi a vencedora\n",
    "# Este Ã© um insight MUITO importante para trading!\n",
    "df_vencedoras['Session'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36db3787",
   "metadata": {},
   "source": [
    "### ğŸ“Š Insight Importante!\n",
    "\n",
    "A distribuiÃ§Ã£o das sessÃµes vencedoras mostra algo interessante:\n",
    "- **Londres**: ~46% (mais frequente)\n",
    "- **NY**: ~42%\n",
    "- **Ãsia**: ~12% (raramente vence)\n",
    "\n",
    "**ConclusÃ£o para trading**: Para EURUSD, focar em Londres e NY faz muito mais sentido\n",
    "do que operar na sessÃ£o asiÃ¡tica!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902633e",
   "metadata": {},
   "source": [
    "## 9. PREPARAÃ‡ÃƒO FINAL DOS DADOS\n",
    "\n",
    "Agora precisamos:\n",
    "1. Adicionar o dia da semana como feature\n",
    "2. Fazer merge para adicionar o 'Target' (sessÃ£o vencedora) ao dataset principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d202ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ADIÃ‡ÃƒO DO DIA DA SEMANA\n",
    "# ============================================================\n",
    "\n",
    "# Reset do Ã­ndice para ter Data e Session como colunas\n",
    "df_session = df_session.reset_index()\n",
    "\n",
    "# Extrai o dia da semana (0=Segunda, 1=TerÃ§a, ..., 6=Domingo)\n",
    "# Isso pode revelar padrÃµes como \"NY performa melhor nas sextas\"\n",
    "df_session['DiaSemana'] = df_session['Data'].apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5e4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ceeeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MERGE: ADICIONA O TARGET AO DATAFRAME PRINCIPAL\n",
    "# ============================================================\n",
    "\n",
    "# Merge junta duas tabelas baseado em uma coluna comum\n",
    "# Aqui, para cada Data em df_session, pegamos a Session vencedora de df_vencedoras\n",
    "# how='left' mantÃ©m todas as linhas de df_session mesmo se nÃ£o houver match\n",
    "df_session = df_session.merge(df_vencedoras, on='Data', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b190bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba2576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RENOMEAÃ‡ÃƒO DAS COLUNAS\n",
    "# ============================================================\n",
    "\n",
    "# ApÃ³s o merge, temos Session_x (sessÃ£o atual) e Session_y (sessÃ£o vencedora)\n",
    "# Renomeamos para nomes mais claros\n",
    "df_session = df_session.rename(columns={\n",
    "    'Session_x': 'Session',  # SessÃ£o da linha atual\n",
    "    'Session_y': 'Target'    # SessÃ£o vencedora do dia (o que queremos prever)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f8d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_session.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eaef35",
   "metadata": {},
   "source": [
    "## 10. MODELO 1: CLASSIFICAÃ‡ÃƒO\n",
    "\n",
    "### Objetivo\n",
    "Prever qual sessÃ£o serÃ¡ a vencedora do dia.\n",
    "\n",
    "### Tipo de Problema\n",
    "**ClassificaÃ§Ã£o Multiclasse** - Temos 3 classes possÃ­veis: asia, london, ny\n",
    "\n",
    "### Features (X) vs Target (y)\n",
    "- **X (features)**: Range, Movimento, Ratio, DiaSemana\n",
    "- **y (target)**: Target (nome da sessÃ£o vencedora)\n",
    "\n",
    "### Train/Test Split\n",
    "Dividimos os dados em:\n",
    "- **70% para treino**: O modelo aprende os padrÃµes\n",
    "- **30% para teste**: Avaliamos se o modelo generaliza\n",
    "\n",
    "**IMPORTANTE**: `shuffle=False` porque sÃ£o dados temporais!\n",
    "NÃ£o podemos usar dados do futuro para prever o passado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db4eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPARAÃ‡ÃƒO DOS DADOS PARA O MODELO DE CLASSIFICAÃ‡ÃƒO\n",
    "# ============================================================\n",
    "\n",
    "# Seleciona as features (variÃ¡veis preditoras)\n",
    "# Usamos Range, Movimento, Ratio e DiaSemana para prever a sessÃ£o vencedora\n",
    "x = df_session[['Range', 'Movimento', 'Ratio', 'DiaSemana']]\n",
    "\n",
    "# Seleciona o target (o que queremos prever)\n",
    "y = df_session['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8514c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DIVISÃƒO TREINO/TESTE\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Divide os dados em treino (70%) e teste (30%)\n",
    "# test_size=0.3: 30% dos dados para teste\n",
    "# shuffle=False: NÃƒO embaralha os dados (CRÃTICO para sÃ©ries temporais!)\n",
    "#   - Se shuffle=True, usarÃ­amos dados de 2018 para prever 2015 (data leakage)\n",
    "# random_state=42: semente para reproducibilidade\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, \n",
    "    test_size=0.3,\n",
    "    shuffle=False,  # IMPORTANTE: manter ordem temporal\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f10e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica as dimensÃµes apÃ³s o split\n",
    "print(f\"Treino: {x_train.shape[0]} amostras\")\n",
    "print(f\"Teste: {x_test.shape[0]} amostras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4645af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TREINAMENTO DO MODELO DE CLASSIFICAÃ‡ÃƒO\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Cria o modelo de Ã¡rvore de decisÃ£o\n",
    "# max_depth=4: limita a profundidade da Ã¡rvore para evitar overfitting\n",
    "#              e facilitar a interpretaÃ§Ã£o\n",
    "mod_arvore = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "\n",
    "# Treina o modelo com os dados de treino\n",
    "# .fit() Ã© onde o modelo \"aprende\" os padrÃµes\n",
    "mod_arvore.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2e560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREVISÃ•ES\n",
    "# ============================================================\n",
    "\n",
    "# Faz previsÃµes nos dados de treino (para comparar com teste)\n",
    "y_pred_train = mod_arvore.predict(x_train)\n",
    "\n",
    "# Faz previsÃµes nos dados de teste (avaliaÃ§Ã£o real)\n",
    "y_pred_test = mod_arvore.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bdab0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AVALIAÃ‡ÃƒO DO MODELO - ACURÃCIA\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# AcurÃ¡cia: percentual de previsÃµes corretas\n",
    "# Comparamos com baseline aleatÃ³rio (33% para 3 classes)\n",
    "acc_train = accuracy_score(y_train, y_pred_train)\n",
    "acc_test = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"AcurÃ¡cia no Treino: {acc_train:.2%}\")\n",
    "print(f\"AcurÃ¡cia no Teste: {acc_test:.2%}\")\n",
    "print(f\"\\nBaseline aleatÃ³rio: 33.33%\")\n",
    "print(f\"Melhoria sobre baseline: {(acc_test - 0.3333) / 0.3333:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8e9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AVALIAÃ‡ÃƒO DO MODELO - MATRIZ DE CONFUSÃƒO\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Matriz de confusÃ£o mostra onde o modelo acerta e erra\n",
    "# Linhas: valores reais | Colunas: valores previstos\n",
    "print(\"Matriz de ConfusÃ£o:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "print(\"\\n\")\n",
    "\n",
    "# RelatÃ³rio detalhado com precision, recall e f1-score\n",
    "print(\"RelatÃ³rio de ClassificaÃ§Ã£o:\")\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0b6590",
   "metadata": {},
   "source": [
    "### InterpretaÃ§Ã£o da Matriz de ConfusÃ£o\n",
    "\n",
    "A matriz de confusÃ£o mostra:\n",
    "- **Diagonal principal**: Acertos (previsÃ£o = real)\n",
    "- **Fora da diagonal**: Erros\n",
    "\n",
    "**MÃ©tricas importantes:**\n",
    "- **Precision**: Dos que o modelo disse que eram X, quantos realmente eram X?\n",
    "- **Recall**: Dos que realmente eram X, quantos o modelo identificou?\n",
    "- **F1-Score**: MÃ©dia harmÃ´nica entre precision e recall\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d389c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZAÃ‡ÃƒO DA ÃRVORE DE DECISÃƒO\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Cria figura grande para melhor visualizaÃ§Ã£o\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Plota a Ã¡rvore de decisÃ£o\n",
    "# feature_names: nomes das features para aparecer nos nÃ³s\n",
    "# class_names: nomes das classes para aparecer nas folhas\n",
    "# filled=True: colore os nÃ³s de acordo com a classe majoritÃ¡ria\n",
    "# rounded=True: bordas arredondadas\n",
    "plot_tree(\n",
    "    mod_arvore,\n",
    "    feature_names=x.columns.tolist(),\n",
    "    class_names=['asia', 'london', 'ny'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "plt.title(\"Ãrvore de DecisÃ£o - ClassificaÃ§Ã£o de SessÃµes EURUSD\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8204693",
   "metadata": {},
   "source": [
    "## 11. MODELO 2: REGRESSÃƒO\n",
    "\n",
    "### Objetivo\n",
    "Prever o tamanho do movimento (em pips) de cada sessÃ£o.\n",
    "\n",
    "### Tipo de Problema\n",
    "**RegressÃ£o** - O target Ã© um valor contÃ­nuo (nÃ£o categorias)\n",
    "\n",
    "### Features (X2) vs Target (y2)\n",
    "- **X2 (features)**: DiaSemana, Session (convertida para nÃºmero)\n",
    "- **y2 (target)**: Movimento (valor contÃ­nuo)\n",
    "\n",
    "### CUIDADO: Evitando Data Leakage!\n",
    "NÃƒO usamos Range ou Ratio como features porque:\n",
    "- Range e Movimento sÃ£o calculados ao mesmo tempo\n",
    "- Usar Range para prever Movimento seria \"trapacear\"\n",
    "- Na vida real, vocÃª nÃ£o sabe o Range antes da sessÃ£o acabar!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d6396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPARAÃ‡ÃƒO DOS DADOS PARA REGRESSÃƒO\n",
    "# ============================================================\n",
    "\n",
    "# Converte Session para nÃºmero (o modelo precisa de dados numÃ©ricos)\n",
    "# asia=0, london=1, ny=2\n",
    "session_map = {'asia': 0, 'london': 1, 'ny': 2}\n",
    "df_session['Session_num'] = df_session['Session'].map(session_map)\n",
    "\n",
    "# Features: apenas DiaSemana e Session_num\n",
    "# NÃƒO usamos Range/Ratio para evitar data leakage!\n",
    "x2 = df_session[['DiaSemana', 'Session_num']]\n",
    "\n",
    "# Target: Movimento (o que queremos prever)\n",
    "y2 = df_session['Movimento']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DIVISÃƒO TREINO/TESTE PARA REGRESSÃƒO\n",
    "# ============================================================\n",
    "\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(\n",
    "    x2, y2,\n",
    "    test_size=0.3,\n",
    "    shuffle=False,  # MantÃ©m ordem temporal\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6c9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TREINAMENTO DO MODELO DE REGRESSÃƒO\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# DecisionTreeRegressor para valores contÃ­nuos\n",
    "# max_depth=4: mesma ideia de limitar complexidade\n",
    "mod_arvore2 = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "\n",
    "# Treina o modelo\n",
    "mod_arvore2.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7522db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREVISÃ•ES DO MODELO DE REGRESSÃƒO\n",
    "# ============================================================\n",
    "\n",
    "y_pred_train2 = mod_arvore2.predict(x_train2)\n",
    "y_pred_test2 = mod_arvore2.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b2950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZAÃ‡ÃƒO DA ÃRVORE DE REGRESSÃƒO\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plot_tree(\n",
    "    mod_arvore2,\n",
    "    feature_names=['DiaSemana', 'Session_num'],\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10\n",
    ")\n",
    "\n",
    "plt.title(\"Ãrvore de DecisÃ£o - RegressÃ£o do Movimento EURUSD\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19846ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPARAÃ‡ÃƒO: VALORES REAIS VS PREVISTOS\n",
    "# ============================================================\n",
    "\n",
    "# Cria DataFrame para comparar previsÃµes com valores reais\n",
    "df2_aval = pd.DataFrame({\n",
    "    'Real': y_test2,\n",
    "    'Previsto': y_pred_test2\n",
    "})\n",
    "df2_aval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca10b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AVALIAÃ‡ÃƒO DO MODELO DE REGRESSÃƒO\n",
    "# ============================================================\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "# MAE (Mean Absolute Error): Erro mÃ©dio em valor absoluto\n",
    "# Quanto menor, melhor\n",
    "mae = metrics.mean_absolute_error(y_test2, y_pred_test2)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "# RMSE (Root Mean Squared Error): Penaliza mais erros grandes\n",
    "rmse = np.sqrt(metrics.mean_squared_error(y_test2, y_pred_test2))\n",
    "print(f'Root Mean Squared Error: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VERIFICAÃ‡ÃƒO DE OVERFITTING\n",
    "# ============================================================\n",
    "\n",
    "# Compara erro no treino vs teste\n",
    "# Se erro_treino << erro_teste: OVERFITTING (modelo decorou os dados)\n",
    "# Se erro_treino â‰ˆ erro_teste: OK (modelo generaliza bem)\n",
    "\n",
    "mae_train = metrics.mean_absolute_error(y_train2, mod_arvore2.predict(x_train2))\n",
    "mae_test = metrics.mean_absolute_error(y_test2, y_pred_test2)\n",
    "\n",
    "print(f'MAE - Treinamento: {mae_train}')\n",
    "print(f'MAE - Teste: {mae_test}')\n",
    "\n",
    "if mae_train * 1.1 < mae_test:\n",
    "    print(\"\\nâš ï¸ ATENÃ‡ÃƒO: PossÃ­vel overfitting!\")\n",
    "else:\n",
    "    print(\"\\nâœ… Modelo generaliza bem (sem overfitting)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# INTERPRETAÃ‡ÃƒO DO ERRO\n",
    "# ============================================================\n",
    "\n",
    "# Calcula o MAE como percentual da mÃ©dia\n",
    "# Isso dÃ¡ uma ideia de quÃ£o \"grande\" Ã© o erro em termos relativos\n",
    "\n",
    "media_movimento = y_test2.mean()\n",
    "print(f\"MÃ©dia do Movimento: {media_movimento}\")\n",
    "print()\n",
    "\n",
    "erro_percentual = mae / media_movimento * 100\n",
    "print(f'O percentual do MAE em relaÃ§Ã£o Ã  mÃ©dia da base:')\n",
    "print(f'{erro_percentual:.2f}%')\n",
    "print()\n",
    "print(f\"InterpretaÃ§Ã£o: O modelo erra em mÃ©dia {erro_percentual:.1f}% do movimento real.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b09b7a",
   "metadata": {},
   "source": [
    "## 12. CONCLUSÃ•ES E PRÃ“XIMOS PASSOS\n",
    "\n",
    "### Resultados do Modelo de ClassificaÃ§Ã£o\n",
    "- **AcurÃ¡cia**: ~41% (vs 33% aleatÃ³rio)\n",
    "- O modelo Ã© ~24% melhor que chute aleatÃ³rio\n",
    "- Londres e NY sÃ£o mais previsÃ­veis que Ãsia\n",
    "\n",
    "### Resultados do Modelo de RegressÃ£o\n",
    "- **MAE**: ~7.5% do movimento mÃ©dio\n",
    "- Sem overfitting (erro treino â‰ˆ erro teste)\n",
    "\n",
    "### Insights para Trading\n",
    "1. **Foque em Londres e NY** para EURUSD - juntas vencem 88% dos dias\n",
    "2. **Ãsia Ã© imprevisÃ­vel** - apenas 12% de vitÃ³rias, modelo falha muito\n",
    "3. **PadrÃµes existem mas sÃ£o fracos** - 41% nÃ£o Ã© suficiente para trading real\n",
    "\n",
    "### PrÃ³ximos Passos\n",
    "1. Adicionar mais features (volatilidade do dia anterior, eventos econÃ´micos)\n",
    "2. Testar outros modelos (Random Forest, XGBoost)\n",
    "3. Fazer backtesting com os sinais gerados\n",
    "4. Incluir custos de transaÃ§Ã£o na avaliaÃ§Ã£o\n",
    "\n",
    "---\n",
    "\n",
    "**Leonardo Alves**: Dados, nÃ£o opiniÃµes! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
